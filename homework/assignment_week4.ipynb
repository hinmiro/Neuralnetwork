{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d517db5c",
   "metadata": {},
   "source": [
    "## Assignment: week 4\n",
    "\n",
    "##### Task\n",
    "\n",
    "With the pretrained GloVe embeddings, find the word vectors for the three words \"man\", \"woman\", and \"king\". With these, calculate the vector obtained from the expression\n",
    "\n",
    "vec(\"woman\") - vec(\"man) + vec(\"king\")\n",
    "\n",
    "and find the nearest vector(s) to it, using the cosine similarity as the distance measure. You can use the code in weekly material as the starting point.\n",
    "\n",
    "Can you explain your result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d2660",
   "metadata": {},
   "source": [
    "#### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6ff732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda_env\\Densor\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\M_Hin\\.cache\\kagglehub\\datasets\\anmolkumar\\glove-embeddings\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"anmolkumar/glove-embeddings\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "glove_file = os.path.join(path, 'glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9e54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "        \n",
    "print(f'Loaded {len(embeddings)} word vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbe49786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words closest to (woman - man + king):\n",
      "queen: 0.7834\n",
      "monarch: 0.6934\n",
      "throne: 0.6833\n",
      "daughter: 0.6809\n",
      "prince: 0.6713\n",
      "princess: 0.6644\n",
      "mother: 0.6579\n",
      "elizabeth: 0.6563\n",
      "father: 0.6392\n",
      "wife: 0.6352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get the vectors for the words\n",
    "man_vector = embeddings.get('man')\n",
    "woman_vector = embeddings.get('woman')\n",
    "king_vector = embeddings.get('king')\n",
    "\n",
    "if man_vector is None or woman_vector is None or king_vector is None:\n",
    "    print(\"Warning: One or more words not found in the embeddings\")\n",
    "else:\n",
    "    # Calculate the vector: woman - man + king\n",
    "    result_vector = woman_vector - man_vector + king_vector\n",
    "    \n",
    "    # Find the nearest word(s) using cosine similarity\n",
    "    similarities = {}\n",
    "    for word, vector in embeddings.items():\n",
    "        # Calculate cosine similarity between result_vector and each word's vector\n",
    "        # We reshape to get the right dimensions for cosine_similarity\n",
    "        sim = cosine_similarity(result_vector.reshape(1, -1), vector.reshape(1, -1))[0][0]\n",
    "        similarities[word] = sim\n",
    "    \n",
    "    # Sort by similarity\n",
    "    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top 10 words closest to (woman - man + king):\")\n",
    "    for word, sim in sorted_words[1:10+1]:\n",
    "        print(f\"{word}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_similar_words(target_word, top_n=10):\n",
    "    \n",
    "    target_vector = embeddings[target_word]\n",
    "    \n",
    "    if target_word is None: \n",
    "        return f'Word \"{target_word}\" not in vocabulary'\n",
    "    \n",
    "    similarities = {}\n",
    "    for word, vector in embeddings.items():\n",
    "        sim = cosine_similarity(target_vector.reshape(1, -1), vector.reshape(1, -1))\n",
    "        similarities[word] = sim\n",
    "    \n",
    "    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_words[top_n+1]\n",
    "    \n",
    "similar_words = find_similar_words(\"code\")\n",
    "print(f\"Words similar to {similar_words}\")\n",
    "for word, sim in similar_words:\n",
    "    print(f'{word}: {sim:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb02f248",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similar_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43msimilar_words\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'similar_words' is not defined"
     ]
    }
   ],
   "source": [
    "print(similar_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
