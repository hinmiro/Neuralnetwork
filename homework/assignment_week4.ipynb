{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d517db5c",
   "metadata": {},
   "source": [
    "## Assignment: week 4\n",
    "\n",
    "##### Task\n",
    "\n",
    "With the pretrained GloVe embeddings, find the word vectors for the three words \"man\", \"woman\", and \"king\". With these, calculate the vector obtained from the expression\n",
    "\n",
    "vec(\"woman\") - vec(\"man) + vec(\"king\")\n",
    "\n",
    "and find the nearest vector(s) to it, using the cosine similarity as the distance measure. You can use the code in weekly material as the starting point.\n",
    "\n",
    "Can you explain your result?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8d2660",
   "metadata": {},
   "source": [
    "#### Use Torch for Faster Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57368ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71388912",
   "metadata": {},
   "source": [
    "#### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af6ff732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\M_Hin\\.cache\\kagglehub\\datasets\\anmolkumar\\glove-embeddings\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"anmolkumar/glove-embeddings\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "glove_file = os.path.join(path, 'glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f9e54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "        \n",
    "print(f'Loaded {len(embeddings)} word vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc39d357",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe49786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen: 0.7834\n",
      "monarch: 0.6934\n",
      "throne: 0.6833\n",
      "daughter: 0.6809\n",
      "prince: 0.6713\n",
      "princess: 0.6644\n",
      "mother: 0.6579\n",
      "elizabeth: 0.6563\n",
      "father: 0.6392\n",
      "wife: 0.6352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embeddings_torch = {word: torch.tensor(vec, device=device) for word, vec in embeddings.items()}\n",
    "\n",
    "# Get the vectors for the words\n",
    "man_vector = embeddings_torch.get('man')\n",
    "woman_vector = embeddings_torch.get('woman')\n",
    "king_vector = embeddings_torch.get('king')\n",
    "\n",
    "if man_vector is None or woman_vector is None or king_vector is None:\n",
    "    print(\"Warning: One or more words not found in the embeddings\")\n",
    "else:\n",
    "    result_vector = woman_vector - man_vector + king_vector\n",
    "    \n",
    "    all_words = list(embeddings_torch.keys())\n",
    "    all_vectors = torch.stack([embeddings_torch[word] for word in all_words])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    result_vector_norm = result_vector / result_vector.norm()\n",
    "    all_vectors_norm = all_vectors / all_vectors.norm(dim=1, keepdim=True)\n",
    "    similarities = torch.matmul(all_vectors_norm, result_vector_norm)\n",
    "\n",
    "    # Get top 10 most similar words (excluding the exact match)\n",
    "    topk = torch.topk(similarities, 11)\n",
    "    for idx, score in zip(topk.indices[1:], topk.values[1:]):\n",
    "        print(f\"{all_words[idx]}: {score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560bf8a",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "Model captures relationships between word vectors and can this way calculate the nearest similar vector (which represents word).\n",
    "\n",
    "When we do the calculation **vec(\"woman\") - vec(\"man\") + vec(\"king\")**, we get a vector close to **\"queen\"**. This shows that the model understands the relationship between these words, such as \"king\" is to \"queen\" as \"man\" is to \"woman\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
