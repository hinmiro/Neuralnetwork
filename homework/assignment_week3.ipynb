{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2d0ce4b",
   "metadata": {},
   "source": [
    "## Week 3 Assignment\n",
    "\n",
    "#### Task\n",
    "\n",
    "In the course material, a simple convolutional neural network is built, trained and tested to solve the multiclass classification task presented by the CIFAR-10 dataset. To improve the accuracy, you should experiment with pre trained models. Follow the instructions in Chollet's book \"Deep Learning with Python\", 2nd edition, Chapter 8, pp. 225-231: Feature extraction with a pre trained model. Pick one of the pre trained models available with Keras, and discard the Dense classifier top. You should only use the convolution base to preprocess the original images to a new representation, using its predict method. For this modified input data, you should build a simple fully connected classifier, train it, and test it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec2254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=77)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e503f2",
   "metadata": {},
   "source": [
    "#### Model Creation and Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daacf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 1/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 2/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 3/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 4/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 5/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 6/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 7/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 8/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 9/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 10/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 11/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 12/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 13/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 14/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 15/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 16/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 17/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 18/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 19/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 20/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 21/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Processed batch 22/1250\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Processed batch 23/1250\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Resizing\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications import VGG16\n",
    "\n",
    "\n",
    "# Define feature extractor\n",
    "base_model = VGG16(include_top=False, weights=\"imagenet\")\n",
    "base_model.trainable = False\n",
    "\n",
    "# Define a batch processing\n",
    "def process_images_in_batches(images, labels, batch_size=32):\n",
    "    resize_layer = Resizing(224, 224)\n",
    "    features_list = []\n",
    "    total_batches = len(images) // batch_size + (1 if len(images) % batch_size > 0 else 0)\n",
    "    \n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i + batch_size].astype('float32')\n",
    "        \n",
    "        # Resize\n",
    "        batch_resized = resize_layer(batch_images)\n",
    "        \n",
    "        # Preprocess for VGG16\n",
    "        batch_preprocessed = preprocess_input(batch_resized)\n",
    "        \n",
    "        # Extract features\n",
    "        batch_features = base_model.predict(batch_preprocessed, verbose=1)\n",
    "        \n",
    "        # Flatten features\n",
    "        batch_features_flat = batch_features.reshape(batch_features.shape[0], -1)\n",
    "        features_list.append(batch_features_flat)\n",
    "        \n",
    "        print(f\"Processed batch {i//batch_size + 1}/{total_batches}\")\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    features = np.concatenate(features_list)\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# Process training, validation and test data\n",
    "print(\"Processing training data...\")\n",
    "train_features, train_labels = process_images_in_batches(x_train, y_train)\n",
    "print(\"Processing validation data...\")\n",
    "val_features, val_labels = process_images_in_batches(x_val, y_val)\n",
    "print(\"Processing test data...\")\n",
    "test_features, test_labels = process_images_in_batches(x_test, y_test)\n",
    "\n",
    "# Print shapes to confirm processing worked\n",
    "print(f\"Train features shape: {train_features.shape}, labels shape: {train_labels.shape}\")\n",
    "print(f\"Validation features shape: {val_features.shape}, labels shape: {val_labels.shape}\")\n",
    "print(f\"Test features shape: {test_features.shape}, labels shape: {test_labels.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
